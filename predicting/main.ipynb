{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33fbeee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: post_2026_predictions_main.csv\n",
      "Holdout models: 7 | Random models: 7 | Total: 14\n",
      "Columns: ['home_team', 'away_team', 'prediction_spread_holdout_ElasticNet', 'prediction_spread_holdout_GradientBoosting_TUNED', 'prediction_spread_holdout_HuberRegressor', 'prediction_spread_holdout_Lasso', 'prediction_spread_holdout_LinearRegression', 'prediction_spread_holdout_RandomForest', 'prediction_spread_holdout_Ridge', 'prediction_spread_random_ElasticNet', 'prediction_spread_random_GradientBoosting_TUNED', 'prediction_spread_random_HuberRegressor', 'prediction_spread_random_Lasso', 'prediction_spread_random_LinearRegression', 'prediction_spread_random_RandomForest', 'prediction_spread_random_Ridge', 'avg_holdout', 'avg_random', 'avg_all']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "DATA_FILE = \"post_info_2026_diff.csv\"              # the feature file you want to predict on\n",
    "OUT_FILE  = \"post_2026_predictions_main.csv\"      # output\n",
    "\n",
    "HOLDOUT_DIR = \"models_holdout\"\n",
    "RANDOM_DIR  = \"models_random\"\n",
    "\n",
    "# Optional: keep identifiers in the output (add/remove as you like)\n",
    "ID_COLS = [c for c in [\"home_team\", \"away_team\"] if c in pd.read_csv(DATA_FILE, nrows=1).columns]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# HELPERS\n",
    "# =========================\n",
    "def predict_from_bundle(bundle, df_features: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"Predict using a saved bundle dict from our earlier scripts.\"\"\"\n",
    "    model = bundle[\"model\"]\n",
    "    feats = bundle[\"features\"]\n",
    "    scaler = bundle.get(\"scaler\", None)\n",
    "    numeric_cols = bundle.get(\"numeric_cols\", [])\n",
    "\n",
    "    # Build X in the exact training feature order\n",
    "    missing = [c for c in feats if c not in df_features.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns required by model {bundle.get('model_name','?')}: {missing}\")\n",
    "\n",
    "    X = df_features[feats].copy().apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Apply scaler if stored (linear/huber models)\n",
    "    if scaler is not None and numeric_cols:\n",
    "        X[numeric_cols] = scaler.transform(X[numeric_cols])\n",
    "\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "def load_and_predict_dir(model_dir: str, tag: str, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads every .joblib bundle in model_dir and returns a dataframe of predictions.\n",
    "    Column naming:\n",
    "      prediction_spread_{tag}_{modelname}\n",
    "    where modelname strips any leading 'holdout_' or 'random_'.\n",
    "    \"\"\"\n",
    "    preds = {}\n",
    "\n",
    "    for path in sorted(glob.glob(os.path.join(model_dir, \"*.joblib\"))):\n",
    "        bundle = joblib.load(path)\n",
    "\n",
    "        # Determine a stable name\n",
    "        raw_name = bundle.get(\"model_name\", os.path.splitext(os.path.basename(path))[0])\n",
    "\n",
    "        # Strip prefixes to keep the column readable\n",
    "        base_name = raw_name\n",
    "        if base_name.lower().startswith(\"holdout_\"):\n",
    "            base_name = base_name[len(\"holdout_\"):]\n",
    "        if base_name.lower().startswith(\"random_\"):\n",
    "            base_name = base_name[len(\"random_\"):]\n",
    "\n",
    "        col = f\"prediction_spread_{tag}_{base_name}\"\n",
    "        preds[col] = predict_from_bundle(bundle, df)\n",
    "\n",
    "    return pd.DataFrame(preds)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# MAIN\n",
    "# =========================\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# Make predictions from all models\n",
    "pred_holdout = load_and_predict_dir(HOLDOUT_DIR, \"holdout\", df)\n",
    "pred_random  = load_and_predict_dir(RANDOM_DIR,  \"random\",  df)\n",
    "\n",
    "# Combine into one output\n",
    "out = pd.DataFrame()\n",
    "if ID_COLS:\n",
    "    out[ID_COLS] = df[ID_COLS]\n",
    "\n",
    "out = pd.concat([out, pred_holdout, pred_random], axis=1)\n",
    "\n",
    "# Averages\n",
    "holdout_cols = [c for c in out.columns if c.startswith(\"prediction_spread_holdout_\")]\n",
    "random_cols  = [c for c in out.columns if c.startswith(\"prediction_spread_random_\")]\n",
    "all_pred_cols = holdout_cols + random_cols\n",
    "\n",
    "out[\"avg_holdout\"] = out[holdout_cols].mean(axis=1) if holdout_cols else np.nan\n",
    "out[\"avg_random\"]  = out[random_cols].mean(axis=1) if random_cols else np.nan\n",
    "out[\"avg_all\"]     = out[all_pred_cols].mean(axis=1) if all_pred_cols else np.nan\n",
    "\n",
    "# Save\n",
    "out.to_csv(OUT_FILE, index=False)\n",
    "\n",
    "print(f\"✅ Saved: {OUT_FILE}\")\n",
    "print(f\"Holdout models: {len(holdout_cols)} | Random models: {len(random_cols)} | Total: {len(all_pred_cols)}\")\n",
    "print(\"Columns:\", list(out.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "596f8c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: post_2026_predictions_main.csv\n",
      "Wrote these key columns:\n",
      " - pred_main_holdout_lasso (MAIN)\n",
      " - avg_holdout_top4 (recommended ensemble)\n",
      " - median_holdout_top4 (robust ensemble)\n",
      " - pred_alt_random_gb (alternative / market check)\n",
      " - avg_holdout_all, avg_random_all, avg_all_models (optional diagnostics)\n",
      " - final_pred (currently = pred_main_holdout_lasso)\n",
      " - final_ci_lb, final_ci_ub (currently = holdout_Lasso interval)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ======================================================\n",
    "# CONFIG\n",
    "# ======================================================\n",
    "DATA_FILE = \"post_info_2026_diff.csv\"\n",
    "OUT_FILE  = \"post_2026_predictions_main.csv\"\n",
    "\n",
    "HOLDOUT_DIR = \"models_holdout\"\n",
    "RANDOM_DIR  = \"models_random\"\n",
    "\n",
    "ID_COLS = [\"home_team\", \"away_team\"]  # kept if present\n",
    "\n",
    "# ======================================================\n",
    "# HELPERS\n",
    "# ======================================================\n",
    "def _get_base_name(raw_name: str) -> str:\n",
    "    base = raw_name or \"\"\n",
    "    low = base.lower()\n",
    "    if low.startswith(\"holdout_\"):\n",
    "        base = base[len(\"holdout_\"):]\n",
    "    elif low.startswith(\"random_\"):\n",
    "        base = base[len(\"random_\"):]\n",
    "    return base\n",
    "\n",
    "\n",
    "def predict_from_bundle(bundle: dict, df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bundle format (your saved joblibs):\n",
    "      {\n",
    "        \"model_name\": str,\n",
    "        \"model\": sklearn estimator OR Pipeline,\n",
    "        \"features\": [..],\n",
    "        \"numeric_cols\": [..],\n",
    "        \"binary_cols\": [..],\n",
    "        \"scaler\": StandardScaler or None,\n",
    "        # optional PI fields:\n",
    "        \"pi_halfwidth_q\": float,\n",
    "      }\n",
    "    \"\"\"\n",
    "    model = bundle[\"model\"]\n",
    "    feats = bundle[\"features\"]\n",
    "    scaler = bundle.get(\"scaler\", None)\n",
    "    numeric_cols = bundle.get(\"numeric_cols\", [])\n",
    "\n",
    "    missing = [c for c in feats if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required features for {bundle.get('model_name','?')}: {missing}\")\n",
    "\n",
    "    X = df[feats].copy().apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Linear/HUBER bundles have scaler; tree bundles usually have scaler=None\n",
    "    if scaler is not None and numeric_cols:\n",
    "        X[numeric_cols] = scaler.transform(X[numeric_cols])\n",
    "\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "def load_predictions_and_intervals(model_dir: str, prefix: str, df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Returns dict of columns -> arrays for each joblib in a folder:\n",
    "      - prediction_spread_{prefix}_{BaseModelName}\n",
    "      - ci_lb_{prefix}_{BaseModelName}\n",
    "      - ci_ub_{prefix}_{BaseModelName}\n",
    "\n",
    "    Assumes each bundle includes:\n",
    "      - pi_halfwidth_q (from your training script)\n",
    "    \"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(model_dir, \"*.joblib\")))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No .joblib files found in: {model_dir}\")\n",
    "\n",
    "    out = {}\n",
    "    for p in paths:\n",
    "        bundle = joblib.load(p)\n",
    "\n",
    "        raw_name = bundle.get(\"model_name\", os.path.splitext(os.path.basename(p))[0])\n",
    "        base = _get_base_name(raw_name)\n",
    "\n",
    "        pred_col = f\"prediction_spread_{prefix}_{base}\"\n",
    "        lb_col   = f\"ci_lb_{prefix}_{base}\"\n",
    "        ub_col   = f\"ci_ub_{prefix}_{base}\"\n",
    "\n",
    "        preds = predict_from_bundle(bundle, df)\n",
    "\n",
    "        q = bundle.get(\"pi_halfwidth_q\", None)\n",
    "        if q is None or (isinstance(q, float) and np.isnan(q)):\n",
    "            # If PI wasn't stored, still create cols but leave NA\n",
    "            lb = np.full_like(preds, np.nan, dtype=float)\n",
    "            ub = np.full_like(preds, np.nan, dtype=float)\n",
    "        else:\n",
    "            q = float(q)\n",
    "            lb = preds - q\n",
    "            ub = preds + q\n",
    "\n",
    "        out[pred_col] = preds\n",
    "        out[lb_col]   = lb\n",
    "        out[ub_col]   = ub\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MAIN\n",
    "# ======================================================\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# Keep IDs (if present)\n",
    "id_cols = [c for c in ID_COLS if c in df.columns]\n",
    "out = df[id_cols].copy() if id_cols else pd.DataFrame(index=df.index)\n",
    "\n",
    "# 1) Load all predictions + intervals\n",
    "holdout_cols = load_predictions_and_intervals(HOLDOUT_DIR, \"holdout\", df)\n",
    "random_cols  = load_predictions_and_intervals(RANDOM_DIR,  \"random\",  df)\n",
    "\n",
    "out = pd.concat([out, pd.DataFrame(holdout_cols), pd.DataFrame(random_cols)], axis=1)\n",
    "\n",
    "# 2) “What I’d ship” point prediction columns\n",
    "\n",
    "# MAIN: best holdout model\n",
    "MAIN_COL = \"prediction_spread_holdout_Lasso\"\n",
    "if MAIN_COL not in out.columns:\n",
    "    raise KeyError(f\"Expected main prediction column not found: {MAIN_COL}\")\n",
    "\n",
    "out[\"pred_main_holdout_lasso\"] = out[MAIN_COL]\n",
    "\n",
    "# Safety ensemble: Top-4 holdout linear models\n",
    "top4_cols = [\n",
    "    \"prediction_spread_holdout_Lasso\",\n",
    "    \"prediction_spread_holdout_LinearRegression\",\n",
    "    \"prediction_spread_holdout_Ridge\",\n",
    "    \"prediction_spread_holdout_ElasticNet\",\n",
    "]\n",
    "missing_top4 = [c for c in top4_cols if c not in out.columns]\n",
    "if missing_top4:\n",
    "    raise KeyError(f\"Missing columns needed for avg_holdout_top4: {missing_top4}\")\n",
    "\n",
    "out[\"avg_holdout_top4\"] = out[top4_cols].mean(axis=1)\n",
    "out[\"median_holdout_top4\"] = out[top4_cols].median(axis=1)\n",
    "\n",
    "# Alternative forecast: best random model (GB tuned)\n",
    "ALT_COL = \"prediction_spread_random_GradientBoosting_TUNED\"\n",
    "out[\"pred_alt_random_gb\"] = out[ALT_COL] if ALT_COL in out.columns else np.nan\n",
    "\n",
    "# Optional: diagnostic averages\n",
    "holdout_pred_cols_all = [c for c in out.columns if c.startswith(\"prediction_spread_holdout_\")]\n",
    "random_pred_cols_all  = [c for c in out.columns if c.startswith(\"prediction_spread_random_\")]\n",
    "\n",
    "out[\"avg_holdout_all\"] = out[holdout_pred_cols_all].mean(axis=1) if holdout_pred_cols_all else np.nan\n",
    "out[\"avg_random_all\"]  = out[random_pred_cols_all].mean(axis=1)  if random_pred_cols_all  else np.nan\n",
    "out[\"avg_all_models\"]  = out[holdout_pred_cols_all + random_pred_cols_all].mean(axis=1) if (holdout_pred_cols_all or random_pred_cols_all) else np.nan\n",
    "\n",
    "# 3) Choose a single “final_pred”\n",
    "out[\"final_pred\"] = out[\"pred_main_holdout_lasso\"]\n",
    "# If you want:\n",
    "# out[\"final_pred\"] = out[\"avg_holdout_top4\"]\n",
    "\n",
    "# 4) OPTIONAL: add a “final” interval based on your chosen final_pred\n",
    "# If you want final interval to match MAIN holdout lasso:\n",
    "MAIN_LB = \"ci_lb_holdout_Lasso\"\n",
    "MAIN_UB = \"ci_ub_holdout_Lasso\"\n",
    "if MAIN_LB in out.columns and MAIN_UB in out.columns:\n",
    "    out[\"final_ci_lb\"] = out[MAIN_LB]\n",
    "    out[\"final_ci_ub\"] = out[MAIN_UB]\n",
    "else:\n",
    "    out[\"final_ci_lb\"] = np.nan\n",
    "    out[\"final_ci_ub\"] = np.nan\n",
    "\n",
    "# 5) Write out\n",
    "out.to_csv(OUT_FILE, index=False)\n",
    "print(f\"✅ Saved: {OUT_FILE}\")\n",
    "\n",
    "print(\"Wrote these key columns:\")\n",
    "print(\" - pred_main_holdout_lasso (MAIN)\")\n",
    "print(\" - avg_holdout_top4 (recommended ensemble)\")\n",
    "print(\" - median_holdout_top4 (robust ensemble)\")\n",
    "print(\" - pred_alt_random_gb (alternative / market check)\")\n",
    "print(\" - avg_holdout_all, avg_random_all, avg_all_models (optional diagnostics)\")\n",
    "print(\" - final_pred (currently = pred_main_holdout_lasso)\")\n",
    "print(\" - final_ci_lb, final_ci_ub (currently = holdout_Lasso interval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deb0ee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: post_2026_predictions_main_2.csv\n",
      "\n",
      "Key outputs:\n",
      " - final_pred = 0.60*random_GB + 0.40*holdout_Lasso\n",
      " - final_ci_lb/final_ci_ub centered on final_pred\n",
      " - interval halfwidth uses blended model halfwidths if available, else ±10.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ======================================================\n",
    "# CONFIG\n",
    "# ======================================================\n",
    "DATA_FILE = \"post_info_2026_diff.csv\"\n",
    "OUT_FILE  = \"post_2026_predictions_main_2.csv\"\n",
    "\n",
    "HOLDOUT_DIR = \"models_holdout\"\n",
    "RANDOM_DIR  = \"models_random\"\n",
    "\n",
    "ID_COLS = [\"home_team\", \"away_team\"]  # kept if present\n",
    "\n",
    "# Blending weights (your requested logic)\n",
    "W_RANDOM_GB = 0.60\n",
    "W_HOLDOUT_LASSO = 0.40\n",
    "\n",
    "# Simple fallback halfwidth for final interval (if model-level PI not stored)\n",
    "# Use 10 if you want a safer >=70% coverage baseline.\n",
    "FALLBACK_HALF_WIDTH = 10.0\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# HELPERS\n",
    "# ======================================================\n",
    "def _get_base_name(raw_name: str) -> str:\n",
    "    base = raw_name or \"\"\n",
    "    low = base.lower()\n",
    "    if low.startswith(\"holdout_\"):\n",
    "        base = base[len(\"holdout_\"):]\n",
    "    elif low.startswith(\"random_\"):\n",
    "        base = base[len(\"random_\"):]\n",
    "    return base\n",
    "\n",
    "\n",
    "def predict_from_bundle(bundle: dict, df: pd.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Bundle format (your saved joblibs):\n",
    "      {\n",
    "        \"model_name\": str,\n",
    "        \"model\": sklearn estimator OR Pipeline,\n",
    "        \"features\": [..],\n",
    "        \"numeric_cols\": [..],\n",
    "        \"binary_cols\": [..],\n",
    "        \"scaler\": StandardScaler or None,\n",
    "        # optional PI fields:\n",
    "        \"pi_halfwidth_q\": float,\n",
    "      }\n",
    "    \"\"\"\n",
    "    model = bundle[\"model\"]\n",
    "    feats = bundle[\"features\"]\n",
    "    scaler = bundle.get(\"scaler\", None)\n",
    "    numeric_cols = bundle.get(\"numeric_cols\", [])\n",
    "\n",
    "    missing = [c for c in feats if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing required features for {bundle.get('model_name','?')}: {missing}\")\n",
    "\n",
    "    X = df[feats].copy().apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "    # Linear/HUBER bundles have scaler; tree bundles usually have scaler=None\n",
    "    if scaler is not None and numeric_cols:\n",
    "        X[numeric_cols] = scaler.transform(X[numeric_cols])\n",
    "\n",
    "    return model.predict(X)\n",
    "\n",
    "\n",
    "def load_predictions_and_intervals(model_dir: str, prefix: str, df: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Returns dict of columns -> arrays for each joblib in a folder:\n",
    "      - prediction_spread_{prefix}_{BaseModelName}\n",
    "      - ci_lb_{prefix}_{BaseModelName}\n",
    "      - ci_ub_{prefix}_{BaseModelName}\n",
    "\n",
    "    Assumes each bundle optionally includes:\n",
    "      - pi_halfwidth_q (half-width for target coverage)\n",
    "    \"\"\"\n",
    "    paths = sorted(glob.glob(os.path.join(model_dir, \"*.joblib\")))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"No .joblib files found in: {model_dir}\")\n",
    "\n",
    "    out = {}\n",
    "    for p in paths:\n",
    "        bundle = joblib.load(p)\n",
    "\n",
    "        raw_name = bundle.get(\"model_name\", os.path.splitext(os.path.basename(p))[0])\n",
    "        base = _get_base_name(raw_name)\n",
    "\n",
    "        pred_col = f\"prediction_spread_{prefix}_{base}\"\n",
    "        lb_col   = f\"ci_lb_{prefix}_{base}\"\n",
    "        ub_col   = f\"ci_ub_{prefix}_{base}\"\n",
    "\n",
    "        preds = predict_from_bundle(bundle, df)\n",
    "\n",
    "        q = bundle.get(\"pi_halfwidth_q\", None)\n",
    "        if q is None or (isinstance(q, float) and np.isnan(q)):\n",
    "            # If PI wasn't stored, still create cols but leave NA\n",
    "            lb = np.full_like(preds, np.nan, dtype=float)\n",
    "            ub = np.full_like(preds, np.nan, dtype=float)\n",
    "        else:\n",
    "            q = float(q)\n",
    "            lb = preds - q\n",
    "            ub = preds + q\n",
    "\n",
    "        out[pred_col] = preds\n",
    "        out[lb_col]   = lb\n",
    "        out[ub_col]   = ub\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def safe_mean(a: np.ndarray, b: np.ndarray, wa: float, wb: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Weighted blend with graceful handling of NaN:\n",
    "    - if one side NaN -> use the other\n",
    "    - if both NaN -> NaN\n",
    "    \"\"\"\n",
    "    a = a.astype(float)\n",
    "    b = b.astype(float)\n",
    "    out = np.full_like(a, np.nan, dtype=float)\n",
    "\n",
    "    a_ok = ~np.isnan(a)\n",
    "    b_ok = ~np.isnan(b)\n",
    "\n",
    "    out[a_ok & ~b_ok] = a[a_ok & ~b_ok]\n",
    "    out[~a_ok & b_ok] = b[~a_ok & b_ok]\n",
    "    both = a_ok & b_ok\n",
    "    out[both] = wa * a[both] + wb * b[both]\n",
    "    return out\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# MAIN\n",
    "# ======================================================\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# Keep IDs (if present)\n",
    "id_cols = [c for c in ID_COLS if c in df.columns]\n",
    "out = df[id_cols].copy() if id_cols else pd.DataFrame(index=df.index)\n",
    "\n",
    "# 1) Load all predictions + intervals\n",
    "holdout_cols = load_predictions_and_intervals(HOLDOUT_DIR, \"holdout\", df)\n",
    "random_cols  = load_predictions_and_intervals(RANDOM_DIR,  \"random\",  df)\n",
    "\n",
    "out = pd.concat([out, pd.DataFrame(holdout_cols), pd.DataFrame(random_cols)], axis=1)\n",
    "\n",
    "# 2) “What I’d ship” point prediction columns (kept for diagnostics)\n",
    "MAIN_COL = \"prediction_spread_holdout_Lasso\"\n",
    "ALT_COL  = \"prediction_spread_random_GradientBoosting_TUNED\"\n",
    "\n",
    "if MAIN_COL not in out.columns:\n",
    "    raise KeyError(f\"Expected holdout lasso prediction not found: {MAIN_COL}\")\n",
    "if ALT_COL not in out.columns:\n",
    "    raise KeyError(f\"Expected random GB prediction not found: {ALT_COL}\")\n",
    "\n",
    "out[\"pred_main_holdout_lasso\"] = out[MAIN_COL]\n",
    "out[\"pred_alt_random_gb\"] = out[ALT_COL]\n",
    "\n",
    "# Holdout Top-4 (optional)\n",
    "top4_cols = [\n",
    "    \"prediction_spread_holdout_Lasso\",\n",
    "    \"prediction_spread_holdout_LinearRegression\",\n",
    "    \"prediction_spread_holdout_Ridge\",\n",
    "    \"prediction_spread_holdout_ElasticNet\",\n",
    "]\n",
    "missing_top4 = [c for c in top4_cols if c not in out.columns]\n",
    "if not missing_top4:\n",
    "    out[\"avg_holdout_top4\"] = out[top4_cols].mean(axis=1)\n",
    "    out[\"median_holdout_top4\"] = out[top4_cols].median(axis=1)\n",
    "else:\n",
    "    out[\"avg_holdout_top4\"] = np.nan\n",
    "    out[\"median_holdout_top4\"] = np.nan\n",
    "\n",
    "# Optional: diagnostic averages\n",
    "holdout_pred_cols_all = [c for c in out.columns if c.startswith(\"prediction_spread_holdout_\")]\n",
    "random_pred_cols_all  = [c for c in out.columns if c.startswith(\"prediction_spread_random_\")]\n",
    "\n",
    "out[\"avg_holdout_all\"] = out[holdout_pred_cols_all].mean(axis=1) if holdout_pred_cols_all else np.nan\n",
    "out[\"avg_random_all\"]  = out[random_pred_cols_all].mean(axis=1)  if random_pred_cols_all  else np.nan\n",
    "out[\"avg_all_models\"]  = out[holdout_pred_cols_all + random_pred_cols_all].mean(axis=1) if (holdout_pred_cols_all or random_pred_cols_all) else np.nan\n",
    "\n",
    "# 3) Choose final_pred = 0.6 * random_GB + 0.4 * holdout_Lasso\n",
    "out[\"final_pred\"] = safe_mean(\n",
    "    out[\"pred_alt_random_gb\"].to_numpy(),\n",
    "    out[\"pred_main_holdout_lasso\"].to_numpy(),\n",
    "    W_RANDOM_GB,\n",
    "    W_HOLDOUT_LASSO,\n",
    ")\n",
    "\n",
    "# 4) Final interval: blend model intervals if available; otherwise fallback ±10\n",
    "# Prefer blending the halfwidths (interval sizes), then center on final_pred.\n",
    "\n",
    "lb_gb = f\"ci_lb_random_GradientBoosting_TUNED\"\n",
    "ub_gb = f\"ci_ub_random_GradientBoosting_TUNED\"\n",
    "lb_la = f\"ci_lb_holdout_Lasso\"\n",
    "ub_la = f\"ci_ub_holdout_Lasso\"\n",
    "\n",
    "half_gb = None\n",
    "half_la = None\n",
    "\n",
    "if lb_gb in out.columns and ub_gb in out.columns:\n",
    "    half_gb = (out[ub_gb] - out[lb_gb]) / 2.0\n",
    "if lb_la in out.columns and ub_la in out.columns:\n",
    "    half_la = (out[ub_la] - out[lb_la]) / 2.0\n",
    "\n",
    "if half_gb is not None and half_la is not None:\n",
    "    # Blend halfwidths with same weights (handles NaN safely)\n",
    "    final_half = safe_mean(\n",
    "        half_gb.to_numpy(),\n",
    "        half_la.to_numpy(),\n",
    "        W_RANDOM_GB,\n",
    "        W_HOLDOUT_LASSO,\n",
    "    )\n",
    "elif half_gb is not None:\n",
    "    final_half = half_gb.to_numpy().astype(float)\n",
    "elif half_la is not None:\n",
    "    final_half = half_la.to_numpy().astype(float)\n",
    "else:\n",
    "    final_half = np.full(len(out), FALLBACK_HALF_WIDTH, dtype=float)\n",
    "\n",
    "# If any halfwidth is still NaN, fill with fallback\n",
    "final_half = np.where(np.isnan(final_half), FALLBACK_HALF_WIDTH, final_half)\n",
    "\n",
    "out[\"final_ci_lb\"] = out[\"final_pred\"] - final_half\n",
    "out[\"final_ci_ub\"] = out[\"final_pred\"] + final_half\n",
    "\n",
    "# 5) Write out\n",
    "out.to_csv(OUT_FILE, index=False)\n",
    "print(f\"✅ Saved: {OUT_FILE}\")\n",
    "\n",
    "print(\"\\nKey outputs:\")\n",
    "print(f\" - final_pred = {W_RANDOM_GB:.2f}*random_GB + {W_HOLDOUT_LASSO:.2f}*holdout_Lasso\")\n",
    "print(f\" - final_ci_lb/final_ci_ub centered on final_pred\")\n",
    "print(f\" - interval halfwidth uses blended model halfwidths if available, else ±{FALLBACK_HALF_WIDTH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
